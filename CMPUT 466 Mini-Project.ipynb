{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Problem\n",
    "\n",
    "The dataset is weather data from the edmonton city-center from 1961 to 1994, with the goal to predict weather \"descriptions\" (i.e. cloudy, snow, rain etc) from features (temperature, relhumidity, pressure)\n",
    "\n",
    "\n",
    "## Classifiers\n",
    "I choose 3 classifiers + the baseline to explore the performance of different algorithms, all using the\n",
    "scikit-learn implementations\n",
    "\\begin{itemize}\n",
    "    \\item There's the obvious baseline of a $\\frac{1}{k}$ zero-classifier, which we will hopefully outperform\n",
    "    \\item Linear regression as a basic model\n",
    "    \\item SVM\n",
    "    \\item and a relatively simple multi-layer perceptron neural net from SKLearn\n",
    "\\end{itemize}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, get_scorer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# tqdm loading bars\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "# the size of the test and validation splits\n",
    "TEST_SIZE = 0.2\n",
    "# our random seed to use\n",
    "RANDOM_STATE = 69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We're trying to predict the weather column of this data, which has 178 different labels, which is too much to\n",
    "reasonably classify in this project, so I filter the dataset to only use the top 10 classes, which make up ~95% of the data anyways\n",
    "\n",
    "I also remove any rows containing NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes with counts are : [('Mostly Cloudy', 121373), ('Mainly Clear', 99069), ('Cloudy', 45023), ('Clear', 31173), ('Snow', 25218), ('Rain Showers', 6916), ('Rain', 6347), ('Fog', 5068), ('Ice Crystals', 3636), ('Smoke', 1749)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TempC</th>\n",
       "      <th>RelHumPct</th>\n",
       "      <th>PkPa</th>\n",
       "      <th>Weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.3</td>\n",
       "      <td>96.0</td>\n",
       "      <td>92.59</td>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.9</td>\n",
       "      <td>90.0</td>\n",
       "      <td>92.64</td>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.9</td>\n",
       "      <td>90.0</td>\n",
       "      <td>92.71</td>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>92.79</td>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-11.1</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92.84</td>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361473</th>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>94.63</td>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361474</th>\n",
       "      <td>7.1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>94.60</td>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361475</th>\n",
       "      <td>7.4</td>\n",
       "      <td>37.0</td>\n",
       "      <td>94.60</td>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361476</th>\n",
       "      <td>7.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>94.63</td>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361477</th>\n",
       "      <td>7.1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>94.66</td>\n",
       "      <td>Clear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345546 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TempC  RelHumPct   PkPa Weather\n",
       "0        -8.3       96.0  92.59   Clear\n",
       "1        -8.9       90.0  92.64   Clear\n",
       "2        -8.9       90.0  92.71   Clear\n",
       "3       -10.0       93.0  92.79   Clear\n",
       "4       -11.1       92.0  92.84   Clear\n",
       "...       ...        ...    ...     ...\n",
       "361473    6.0       42.0  94.63   Clear\n",
       "361474    7.1       39.0  94.60   Clear\n",
       "361475    7.4       37.0  94.60   Clear\n",
       "361476    7.2       38.0  94.63   Clear\n",
       "361477    7.1       35.0  94.66   Clear\n",
       "\n",
       "[345546 rows x 4 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in data\n",
    "data = pd.read_csv(\"weather_data.csv\")\n",
    "\n",
    "# extract classes and counts\n",
    "classes, counts = np.unique(data[['Weather']].values, return_counts=True)\n",
    "classes = sorted(list(zip(classes, counts)), key=lambda x: -x[1])[:10]\n",
    "print(\"Classes with counts are : {}\".format(classes))\n",
    "classes = list(map(lambda x: x[0], classes))\n",
    "\n",
    "data = data[['TempC','RelHumPct', 'PkPa', 'Weather']].loc[data['Weather'].isin(classes)].dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['TempC', 'RelHumPct', \"PkPa\"]]\n",
    "y = data[['Weather']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, validation, test\n",
    "I use built-in scikit-learn train_test_split to split the data into train, validation, and test datasets \n",
    "In this step I only split into train and test datasets, since I will be using k-fold validation on the \n",
    "All 3 models will be trained on the same train, test, val datasets to compare effectively\n",
    "\n",
    "I extract both a unscaled X_train... and a \n",
    "scaled X_train_scaled... (using a minmax scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state = RANDOM_STATE)\n",
    "\n",
    "# scale a copy of the data (y is just classes so doesn't need to be scaled)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = min_max_scaler.fit_transform(X)\n",
    "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(X_scaled, y, test_size=TEST_SIZE, random_state = RANDOM_STATE)\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=TEST_SIZE, random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers\n",
    "\n",
    "Here I train, validate and test all 4 classifiers, reporting the accuracy and a balanced accuracy score.\n",
    "I use accuracy here because it's a simple metric to intuitively understand, and balanced accuracy since it averages recall per class, which handles the imbalanced classes a little better\n",
    "differently for different labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Classifier\n",
    "\n",
    "As a baseline, I use the scikit-learn DummyClassifier using the \"most_frequent\" strategy\n",
    "which is simply a max class classifier as well as the \"uniform\" strategy which just generates predictions\n",
    "uniformly at random across the classes\n",
    "\n",
    "I would expect this to perform the worst out of the 4 classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummmy classifier (most frequent) has accuracy 0.352062\n",
      "Dummmy classifier (most frequent) has balanced accuracy score 0.100000\n",
      "\n",
      "Dummmy classifier (uniform) has accuracy 0.100955\n",
      "Dummmy classifier (uniform) has balanced accuracy score 0.101505\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_train, y_train)\n",
    "y_hat = dummy.predict(X_test)\n",
    "print(\"Dummmy classifier (most frequent) has accuracy {:f}\".format(accuracy_score(y_test, y_hat)))\n",
    "print(\"Dummmy classifier (most frequent) has balanced accuracy score {:f}\\n\".format(balanced_accuracy_score(y_test, y_hat)))\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"uniform\", random_state=RANDOM_STATE)\n",
    "dummy.fit(X_train, y_train)\n",
    "y_hat = dummy.predict(X_test)\n",
    "print(\"Dummmy classifier (uniform) has accuracy {:f}\".format(accuracy_score(y_test, y_hat)))\n",
    "print(\"Dummmy classifier (uniform) has balanced accuracy score {:f}\".format(balanced_accuracy_score(y_test, y_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Both the dummmy classifiers perform exactly as well as expected, since ~35% of the data is \"mostly cloudy\" and there are 10 classes so the balanced accuracy score is going to be 10%, and for the uniform classifier, both values are around 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "My first model is a Logistic Regression classifier,\n",
    "I use the scikit-learn LogisticRegressionCV which does cross-fold validation within it, I just use the default\n",
    "stratified k-folds built in which should be good enough. NUM_FOLDS can be tuned as needed, as can MAX_ITER\n",
    "\n",
    "I use the \"saga\" solver since it handles large datasets quite well, and I use balanced_accuracy_score \n",
    "for my scoring, since that's my favoured measure of quality in this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
       "                     max_iter=1000, multi_class='auto', n_jobs=None,\n",
       "                     penalty='l2', random_state=None, refit=True, scoring=None,\n",
       "                     solver='saga', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of validation folds for k-fold cross validation\n",
    "NUM_FOLDS = 5\n",
    "# maximum iterations when training our classifier\n",
    "MAX_ITER = 1000\n",
    "\n",
    "logit = LogisticRegressionCV(cv=NUM_FOLDS, max_iter=MAX_ITER, solver=\"saga\", scoring=get_scorer(\"balanced_accuracy\"))\n",
    "logit.fit(X_train_scaled, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression classifier has accuracy 0.392881\n",
      "Logistic Regression has balanced accuracy score 0.200750\n"
     ]
    }
   ],
   "source": [
    "y_hat = logit.predict(X_test_scaled)\n",
    "print(\"Logistic Regression classifier has accuracy {:f}\".format(accuracy_score(y_test, y_hat)))\n",
    "print(\"Logistic Regression has balanced accuracy score {:f}\".format(balanced_accuracy_score(y_test, y_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "As can be seen, there's a marginal increase in accuracy, with a marked increase in balanced accuracy score\n",
    "but we're still looking at only a ~20% balanced accuracy, which is not yet particularly impressive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n",
    "I use an svm classifier next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
